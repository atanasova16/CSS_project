---
title: "Analysis Bulgaria"
output: html_notebook
---

```{r}
bul <- readxl::read_xlsx("C:/Users/User/Documents/UNITN/Computational social science/bulgaria/final_CITIES.xlsx")

bul$activity_rate <- as.double(bul$activity_rate)
bul$labour_force_thousands <- as.double(bul$labour_force_thousands)
bul$employment_rate <- as.double(bul$employment_rate)
bul$foreign_direct_investment_euro <- as.double(bul$foreign_direct_investment_euro)

apply(bul[,-1], 2, mean)
plot(apply(bul[,-1], 2, mean))
```

Taking a look at the correlation plot.

```{r}
library(ggplot2)
library(ggcorrplot)
ggcorrplot(cor(bul[,-1]), hc.order = TRUE, type = "lower", tl.srt = 90, tl.cex = 8)
cor_pmat(bul[,-1])

```

PCA

```{r}
pr.out <- prcomp(bul[,-1] , scale = TRUE)
plot(pr.out)
pr.out$rotation
dim(pr.out$x)
biplot(pr.out , scale = 0)

pr.out$rotation = -pr.out$rotation
pr.out$x = -pr.out$x
biplot(pr.out , scale = 0)

pr.out$sdev

#The variance explained by each principal component is obtained by squaring
#these:
pr.var <- pr.out$sdev^2
pr.var
#explained var
pve <- pr.var / sum(pr.var)
pve
```

```{r}
library(ggpubr)


p1 <- ggplot(data = as.data.frame(pve), aes(x = seq(1:28), y = pve)) + 
        geom_point() +
        #geom_line() +
        #geom_segment(aes(x = 5, y = 0, xend = 5, yend = pve[5])) +
        #geom_segment(aes(x = 0, y = pve[5], xend = 5, yend = pve[5])) +
        xlab("Principal Component") +
        ylab("Proportion of Variance Explained") +
        scale_x_continuous(expand = c(0.01,0)) +
        scale_y_continuous(expand = c(0.05, 0), limits = c(0,1)) +
        theme_classic() 

p2 <- ggplot(data = as.data.frame(cumsum(pve)), aes(x = seq(1:28), y = cumsum(pve))) + 
        geom_point() +
        geom_line() +
        geom_segment(aes(x = 5, y = 0, xend = 5, yend = cumsum(pve)[5])) +
        geom_segment(aes(x = 0, y = cumsum(pve)[5], xend = 5, yend = cumsum(pve)[5])) +
        xlab("Principal Component") +
        ylab("Cumulative Proportion of Variance Explained") +
        scale_x_continuous(expand = c(0,0)) +
        scale_y_continuous(expand = c(0, 0)) +
        theme_classic()

ggarrange(p1, p2)
```


```{r}
comp <- data.frame(pr.out$x[,1:5])

#write.csv(comp, "C:/Users/User/Documents/UNITN/Computational social science/bulgariafirst5PCs.csv")
plot(comp, pch=16, col=rgb(0,0,0,0.5))
#outlier in all the dimensions, and some grouping in the different projections.

summary(pr.out)
bul_transform <- as.data.frame(-pr.out$x[,1:5])
```

#Clustering k-means

```{r}
library(factoextra)
fviz_nbclust(bul_transform, kmeans, method = 'wss')
fviz_nbclust(bul_transform, kmeans, method = 'silhouette')
fviz_nbclust(bul_transform, kmeans, method = 'gap_stat')


```

```{r}
k = 4
kmeans_bul = kmeans(bul_transform, centers = k, nstart = 20)
fviz_cluster(kmeans_bul, data = bul_transform) + theme_classic()
```

```{r}
set.seed(21)
k <- kmeans(comp, 4, nstart=25, iter.max=1000)
library(RColorBrewer)
library(scales)
palette(alpha(brewer.pal(9,'Set1'), 0.5))
plot(comp, col=k$clust, pch=16)

clusters_kmeans4 <- k$cluster
```

```{r}
bul_with_labels <- bul[,]
bul_with_labels$kmeans4 <- as.factor(clusters_kmeans4)

scaled <- as.data.frame(scale(bul_with_labels[,-c(1,30)]))
scaled$Region <- bul$Region
scaled$kmeans4 <- as.factor(clusters_kmeans4)
```

Random forest with previously found clusters. Turning to supervised method to see variable importance

```{r}
library(randomForest)
set.seed(21)
rf_bul <- randomForest(kmeans4 ~.-Region, data = scaled, mtry = 9, importance = TRUE) 
importance(rf_bul)
varImpPlot(rf_bul)
```

```{r}
boxplot(bul_with_labels$connected_to_wastewater_collecting ~ bul_with_labels$kmeans4,
        xlab='Cluster', ylab='connected_to_wastewater_collecting',
        main='connected_to_wastewater_collecting by Cluster')
boxplot(bul$employment_rate ~ bul_with_labels$kmeans4,
        xlab='Cluster', ylab='employment_rate',
        main='employment_rate by Cluster')

ggplot(bul_with_labels, aes(x=kmeans4, y=connected_to_wastewater_collecting, fill = kmeans4)) +
    geom_boxplot(varwidth = TRUE, alpha=0.5) +
    theme(legend.position="none") +
        scale_fill_manual(values = c("#f6d543", "#c53c74", "#2f0a5b", "#f98e09")) +
        theme_classic() +
        ggtitle("Connection to wastewater collection system by cluster")


```

```{r}
rownames(scaled) <- scaled$Region
rownames(bul_transform) <- scaled$Region
```

#Hierarchical clustering

```{r}
set.seed(21)
distmatrix2 <- dist(bul_transform)
hc2 <- hclust(distmatrix2, method = "complete")
plot(hc2, labels = scaled$Region)
labs_pca_hc4 <- cutree(hc2, 4)


#hc2$labels <- as.vector(bul_with_labels[hc2$order, 'Region'])
fviz_dend(hc2,cex = 0.5, k = 4,rect = TRUE)
```

```{r}
#See var importance when hclust
set.seed(21)
rf_bul2 <- randomForest(labs_pca_hc4 ~.-Region - kmeans4, data = scaled, mtry = 9, importance = TRUE)
importance(rf_bul2)
varImpPlot(rf_bul2)
```

Align clusters of the two methods

```{r}
i = labs_pca_hc4 == 1
j = labs_pca_hc4 == 3
v = labs_pca_hc4 == 4
labs_pca_hc4[i] = 3
labs_pca_hc4[j] = 4
labs_pca_hc4[v] = 1
```

```{r}
labs_pca_hc4 == clusters_kmeans4
sum(labs_pca_hc4 == clusters_kmeans4)
table(labs_pca_hc4, clusters_kmeans4)
bul_with_labels$labs_pca_hc4 <- as.factor(labs_pca_hc4)
scaled$labs_pca_hc4 <- as.factor(labs_pca_hc4)
```

```{r}
mclust::adjustedRandIndex(clusters_kmeans4, labs_pca_hc4)
#describe what it is and how it is calculated
```

```{r}
par(mfrow = c(1,2))

boxplot(bul_with_labels$connected_to_wastewater_collecting ~ bul_with_labels$kmeans4,
        xlab='Cluster', ylab='connected_to_wastewater_collecting',
        main='connected_to_wastewater_collecting by Cluster kmeans')
boxplot(bul_with_labels$connected_to_wastewater_collecting ~ bul_with_labels$labs_pca_hc4,
        xlab='Cluster', ylab='connected_to_wastewater_collecting',
        main='connected_to_wastewater_collecting by Cluster hclust')

boxplot(bul$employment_rate ~ bul_with_labels$kmeans4,
        xlab='Cluster', ylab='employment_rate',
        main='employment_rate by Cluster kmeans')

boxplot(bul$employment_rate ~ bul_with_labels$labs_pca_hc4,
        xlab='Cluster', ylab='employment_rate',
        main='employment_rate by Cluster hclust')

boxplot(bul$activity_rate ~ bul_with_labels$kmeans4,
        xlab='Cluster', ylab='activity_rate',
        main='activity_rate by Cluster kmeans')

boxplot(bul$activity_rate ~ bul_with_labels$labs_pca_hc4,
        xlab='Cluster', ylab='activity_rate',
        main='activity_rate by Cluster hclust')


par(mfrow = c(1,1))
```

```{r}
p1 <- ggplot(bul_with_labels, aes(x=kmeans4, y=employment_rate, fill = kmeans4)) +
    geom_boxplot(varwidth = TRUE, alpha=0.5) +
    theme(legend.position="none") +
        scale_fill_manual(values = c("#f6d543", "#c53c74", "#2f0a5b", "#f98e09")) +
        theme_classic() +
        ggtitle("Employment rate by cluster K-means")
p2 <- ggplot(bul_with_labels, aes(x=labs_pca_hc4, y=employment_rate, fill = labs_pca_hc4)) +
    geom_boxplot(varwidth = TRUE, alpha=0.5) +
    theme(legend.position="none") +
        scale_fill_manual(values = c("#f6d543", "#c53c74", "#2f0a5b", "#f98e09")) +
        theme_classic() +
        ggtitle("Employment rate by cluster Hierarchical clustering")
ggarrange(p1, p2)

p1 <- ggplot(bul_with_labels, aes(x=kmeans4, y=activity_rate, fill = kmeans4)) +
    geom_boxplot(varwidth = TRUE, alpha=0.5) +
    theme(legend.position="none") +
        scale_fill_manual(values = c("#f6d543", "#c53c74", "#2f0a5b", "#f98e09")) +
        theme_classic() +
        ggtitle("Activity rate by cluster K-means")
p2 <- ggplot(bul_with_labels, aes(x=labs_pca_hc4, y=activity_rate, fill = labs_pca_hc4)) +
    geom_boxplot(varwidth = TRUE, alpha=0.5) +
    theme(legend.position="none") +
        scale_fill_manual(values = c("#f6d543", "#c53c74", "#2f0a5b", "#f98e09")) +
        theme_classic() +
        ggtitle("Activity rate by cluster Hierarchical clustering")


ggarrange(p1, p2)
```



```{r}
ggplot(bul_with_labels, aes(Population2021, colour = kmeans4)) +
        geom_density()

ggplot(bul_with_labels, aes(x = kmeans4, y = Population2021)) +
        geom_bar(
                aes(color = Region, fill = Region),
                stat = "summary", position = position_stack()
        ) +
        theme_classic()

ggplot(bul_with_labels, aes(x = kmeans4, y = activity_rate)) +
        geom_bar(
                aes(fill = kmeans4),
                #aes(color = Region, fill = Region),
                stat = "summary", position = position_stack()
        ) +
        theme_classic()

ggplot(bul_with_labels, aes(x = kmeans4, y = connected_to_wastewater_collecting)) +
        geom_bar(
                aes(fill = kmeans4),
                #aes(color = Region, fill = Region),
                stat = "summary", position = position_stack()
        ) +
        theme_classic()

```

```{r}
#To see which cities are classified differently
bul_with_labels$Region[bul_with_labels$kmeans4 == 2 & bul_with_labels$labs_pca_hc4 == 3]

```


#Lasso and Ridge regression

Nested Cross Validation: model selection and model asessment. To choose the optimal lambda, and to have a picture of the medium test error rate.

```{r}
library(caret)
library(glmnet)

set.seed(21)
outfolds <- caret::createFolds(scaled$employment_rate ,k = 5, returnTrain = FALSE)
errors_folds_las <- c()
 errors_folds_rid <- c()

for (outfold in outfolds){
        tr <- scaled[-outfold,]
        ts <- scaled[outfold,]
        y_test <- scaled[outfold,16]
        y_train <- scaled[-outfold,16]
        
        #takinga as a variable the region according to kmeans
        x_train <- model.matrix(employment_rate ~ .-Region - labs_pca_hc4, data = tr) #[,-c(16,29,30,31)]
        x_test <- model.matrix(employment_rate ~ .-Region - labs_pca_hc4, data = ts) #[,-c(16,29,30,31)]
        #print(colnames(x_train))
        cv.las <- cv.glmnet(x_train, y_train, alpha = 1, nfolds = 5)

        las <- glmnet(x_train, y_train, alpha = 1)

        plot(cv.las)
        bestlam = cv.las$lambda.min

        las_predict <- predict(las, s = bestlam, newx = x_test)
        #print(las_predict)
        #print(dim(las_predict))
        #print(y_test)
        #print(length(y_test))
        err <- mean((as.data.frame(las_predict)$s1 - y_test)^2)
        print(err)
        errors_folds_las <- c(errors_folds_las, err)
        
        #RIDGE
        cv.rid <- cv.glmnet(x_train, y_train, alpha = 0, nfolds = 5)

        rid <- glmnet(x_train, y_train, alpha = 0)

        plot(cv.rid)
        bestlam = cv.rid$lambda.min

        rid_predict <- predict(rid, s = bestlam, newx = x_test)
        #print(las_predict)
        #print(dim(las_predict))
        #print(y_test)
        #print(length(y_test))
        err2 <- mean((as.data.frame(rid_predict)$s1 - y_test)^2)
        print(err2)
        errors_folds_rid <- c(errors_folds_rid, err2)
        
}

#The estimate of the error of the models are:
mean(errors_folds_las)
mean(errors_folds_rid)

```

Just one train-test separation

```{r}
y <- scaled$employment_rate

set.seed(21)
tr <- sample(1:nrow(scaled), 0.8*nrow(scaled))
ts <- -tr
y_test <- y[ts]
y_train <- y[tr]

x <- model.matrix(employment_rate ~ .-Region-labs_pca_hc4, data = scaled) #[,-c(16,29,30,31)]

x_train <- model.matrix(employment_rate ~ .-Region-labs_pca_hc4, data = scaled[tr,]) #[,-c(16,29,30,31)]
x_test <- model.matrix(employment_rate ~ .-Region-labs_pca_hc4, data = scaled[ts,]) #[,-c(16,29,30,31)]
```

```{r}
set.seed(21)
cv.las <- cv.glmnet(x_train, y_train, alpha = 1, nfolds = 5)

las <- glmnet(x_train, y_train, alpha = 1)

plot(cv.las)
bestlam = cv.las$lambda.min

las_predict <- predict(las, s = bestlam, newx = x_test)
mean((las_predict - y_test)^2) #test error based on just one split train-test
```
Fit lasso on full dataset, final model to be used
```{r}
out.cv <- cv.glmnet(x, y, alpha = 1, nfolds = 5)
bestlam <- out.cv$lambda.min
out <- glmnet(x, y, alpha = 1)

las_pred <- predict(out, type = "coefficients", s = bestlam)[1:32,]
las_pred
 
print(las_pred[las_pred != 0]) # These are the most important variables
#Again we see that activity rate is very important, but also ecological assets
#also region cluster!

plot(out, xvar = "lambda", label = TRUE)
```


Some predictions

```{r}

one_x <- model.matrix(employment_rate ~ .-Region - labs_pca_hc4, data = scaled)[1,] #[1,-c(16,29,30,31)]
prediction_new_observation <- predict(out, s = bestlam, newx = one_x)
#This is normalized, so to get employment rate, need to "de-normalize"
mean_empl_rate <- mean(bul_with_labels$employment_rate)
stdev_empl_rate <- sqrt(var(bul_with_labels$employment_rate))
one_y <- prediction_new_observation*stdev_empl_rate + mean_empl_rate
(prediction_new_observation - scaled[1,16])^2 #error for this one

#Let's see what will happen if we increase the activity rate with say 10%
new_x <- bul_with_labels[c(1,2,3),]
new_x$activity_rate <- new_x$activity_rate + 10 
new_x_scaled <- scaled[c(1,2,3),]
new_x_scaled$activity_rate <- (new_x$activity_rate - mean(bul_with_labels$activity_rate))/sqrt(var(bul_with_labels$activity_rate))
new_x_scaled_mm <- model.matrix(employment_rate ~ .-Region-labs_pca_hc4, data = new_x_scaled) #[,-c(16,29,30,31)]
new_scaled_predictions <- predict(out, s = bestlam, newx = new_x_scaled_mm)
new_predictions <- new_scaled_predictions*stdev_empl_rate + mean_empl_rate

#To see the change in the first three cities for example:
bul_with_labels[c(1,2,3),c(1,17)] #this would be before
new_predictions #after increase in activity rate with 10%

```


```{r}
set.seed(21)
cv.ridg <- cv.glmnet(x_train, y_train, alpha = 0, nfolds = 5)

ridg <- glmnet(x_train, y_train, alpha = 0)

plot(cv.ridg)
bestlam = cv.ridg$lambda.min

ridg_predict <- predict(ridg, s = bestlam, newx = x_test)
mean((ridg_predict - y_test)^2)

out.cv <- cv.glmnet(x, y, alpha = 0, nfolds = 5)
bestlam <- out.cv$lambda.min
out <- glmnet(x, y, alpha = 0)
ridg_pred <- predict(out, type = "coefficients", s = bestlam)[1:32,]
ridg_pred
 
plot(out, xvar = "lambda", label = TRUE)

ridg_pred[order(abs(ridg_pred))] #ordering of the coefficients of variables

```




```{r}
write.csv(bul_with_labels, "C:/Users/User/Documents/UNITN/Computational social science/bulgaria/bul_with_labels.csv")
```







